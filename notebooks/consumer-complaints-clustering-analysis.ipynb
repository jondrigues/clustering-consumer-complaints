{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROCON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "import tensorboard\n",
    "import re\n",
    "import os\n",
    "import codecs\n",
    "import nltk \n",
    "\n",
    "from nltk.stem import RSLPStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "np.random.seed(13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "allFiles = [\n",
    "    \"data//raw//reclamacoes-fundamentadas-sindec-2012.csv\",\n",
    "    \"data//raw//reclamacoes-fundamentadas-sindec-2013.csv\",\n",
    "    \"data//raw//reclamacoes-fundamentadas-sindec-2014.csv\",\n",
    "    \"data//raw//reclamacoes-fundamentadas-sindec-2015.csv\",\n",
    "    \"data//raw//reclamacoes-fundamentadas-sindec-2016.csv\"    \n",
    "]\n",
    "\n",
    "\n",
    "lista_dfs = []\n",
    "procon = pd.DataFrame()\n",
    "for file in allFiles:\n",
    "    df = pd.read_csv(file, index_col=None, header=0, low_memory=False)\n",
    "    lista_dfs.append(df)\n",
    "procon = pd.concat(lista_dfs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procon data, shape:  (1206072, 23)\n"
     ]
    }
   ],
   "source": [
    "print(\"Procon data, shape: \",  procon.shape)\n",
    "\n",
    "#numSampleRow = 5000\n",
    "#procon = procon.sample(numSampleRow)\n",
    "\n",
    "DescricaoProblema = (procon.iloc[:,19])\n",
    "DescricaoAssunto = (procon.iloc[:,17])\n",
    "\n",
    "DescricaoAssuntoProblema =  DescricaoAssunto + \" \"+ DescricaoProblema\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/hadoopen/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/hadoopen/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package perluniprops to\n",
      "[nltk_data]     /home/hadoopen/nltk_data...\n",
      "[nltk_data]   Package perluniprops is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('perluniprops')\n",
    "\n",
    "\n",
    "#nltk's stopwords\n",
    "stopwords = nltk.corpus.stopwords.words('portuguese')\n",
    "\n",
    "#nltk's SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"portuguese\")\n",
    "\n",
    "#Def of functions to process problems description texts\n",
    "def removeStopWords(sentence):\n",
    "    stopwords1 = nltk.corpus.stopwords.words('portuguese')\n",
    "    phrase = []\n",
    "    for word in sentence:\n",
    "        if word not in stopwords1:\n",
    "            phrase.append(word)\n",
    "    return phrase\n",
    "\n",
    "def tokenizeAndStem(text):\n",
    "    tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in filtered_tokens]\n",
    "    return stems\n",
    "\n",
    "\n",
    "def tokenize(text):\n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    filtered_tokens = []\n",
    "    for token in tokens:\n",
    "        if re.search('[a-zA-Z]', token):\n",
    "            filtered_tokens.append(token)\n",
    "    return filtered_tokens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "words    1176\n",
       "dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize.moses import MosesDetokenizer\n",
    "detokenizer = MosesDetokenizer()\n",
    "\n",
    "vocabularyTokenized = []\n",
    "vocabularyTokenizedAndStemmed = []\n",
    "descricaoAssuntoProblemaAdjusted = []\n",
    "\n",
    "for i in DescricaoAssuntoProblema:\n",
    "    #Not considering 'nan' data\n",
    "    if type(i) == str:\n",
    "        i = i.replace('/', ' ') \n",
    "        i = i.replace('etc', ' ') \n",
    "        \n",
    "        #Remove stopwords and tokenize\n",
    "        newString = detokenizer.detokenize(removeStopWords(tokenize(i)), return_str=True)\n",
    "        descricaoAssuntoProblemaAdjusted.append(newString)\n",
    "        \n",
    "        wordsTokenizedAndStemmed = tokenizeAndStem(newString) \n",
    "        vocabularyTokenizedAndStemmed.extend(wordsTokenizedAndStemmed)\n",
    "        wordsTokenized = tokenize(newString)\n",
    "        vocabularyTokenized.extend(wordsTokenized)\n",
    "    else: #in case of 'nan'\n",
    "        descricaoAssuntoProblemaAdjusted.append(\"\")\n",
    "        vocabularyTokenizedAndStemmed.extend(\"\")\n",
    "        vocabularyTokenized.extend(\"\")\n",
    "        \n",
    "\n",
    "#Vocabulary of dataframe with stemmed vocabulary as index and the tokenized words as the column.\n",
    "vocabularyDescription = pd.DataFrame({\"words\": vocabularyTokenized}, index = vocabularyTokenizedAndStemmed)\n",
    "vocabularyDescription = vocabularyDescription.drop_duplicates()\n",
    "\n",
    "vocabularyDescription.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Vectorizer parameters\n",
    "tfidfVectorizer = TfidfVectorizer(max_df=0.8,\n",
    "                                   min_df=0.01,\n",
    "                                   stop_words=nltk.corpus.stopwords.words('portuguese'),\n",
    "                                   use_idf=True,\n",
    "                                   tokenizer=tokenizeAndStem, ngram_range=(1,3))\n",
    "\n",
    "tfidfMatrix = tfidfVectorizer.fit_transform(descricaoAssuntoProblemaAdjusted) #fit the vectorizer to synopses\n",
    "\n",
    "#Add terms on vocabulary\n",
    "terms = tfidfVectorizer.get_feature_names()      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dimentional reduction\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "tfidfReduced = TruncatedSVD(n_components=2, random_state=0).fit_transform(tfidfMatrix)\n",
    "tfidfEmbedded = TSNE(n_components=2, verbose=2, perplexity=40,).fit_transform(tfidfReduced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting the number of clusters with silhouette analysis\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "\n",
    "rangeClusters = [2, 4, 6, 8, 10, 12, 14, 16, 18, 20, 22, 24, 26, 28, 30, 35, 40, 50, 60, 70, 80, 90, 100]\n",
    "\n",
    "for numberClusters in rangeClusters:\n",
    "    clusterer = KMeans(n_clusters=numberClusters, random_state=10)\n",
    "    cluster_labels = clusterer.fit_predict(tfidfEmbedded)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    silhouette_avg = silhouette_score(tfidfEmbedded, cluster_labels)\n",
    "    print(\"For n clusters =\", numberClusters,\n",
    "          \"The average silhouette_score is :\", silhouette_avg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KMeans Custering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "#Best cluster number based on silhouette analysis\n",
    "numClusters = 80\n",
    "\n",
    "km = KMeans(n_clusters=numClusters)\n",
    "\n",
    "km.fit(tfidfMatrix)\n",
    "\n",
    "clusters = km.labels_.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 0, Count: 9859 \n",
      "Main terms: lavar, lavar, lavar, louça, roupa, roupa,\n",
      "\n",
      "Cluster 1, Count: 7176 \n",
      "Main terms: crédito, crédito, cartão, cartão, crédito, cartão,\n",
      "\n",
      "Cluster 2, Count: 19235 \n",
      "Main terms: entrega, etc, etc, entrega, demora, demora,\n",
      "\n",
      "Cluster 3, Count: 21221 \n",
      "Main terms: produtos, informática, informática, microcomputador, produtos, microcomputador,\n",
      "\n",
      "Cluster 4, Count: 15385 \n",
      "Main terms: banco, banco, comercial, entrega, indevida, retenção,\n",
      "\n",
      "Cluster 5, Count: 43331 \n",
      "Main terms: produtos, produtos, informática, informática, produtos, microcomputador,\n",
      "\n",
      "Cluster 6, Count: 52550 \n",
      "Main terms: fixa, plano, venda, compra, compra, telefone,\n",
      "\n",
      "Cluster 7, Count: 65245 \n",
      "Main terms: interfone, etc, etc, interfone, convencional, telefone,\n",
      "\n",
      "Cluster 8, Count: 12907 \n",
      "Main terms: video-laser, filmadora, video-laser, televisão, televisão, televisão,\n",
      "\n",
      "Cluster 9, Count: 21471 \n",
      "Main terms: serviço, cumprimento, entrega, entrega, instalação, instalação,\n",
      "\n",
      "Cluster 10, Count: 5191 \n",
      "Main terms: cursos, alteração, unilateral, rescisão, rescisão, contrato,\n",
      "\n",
      "Cluster 11, Count: 31871 \n",
      "Main terms: transferencia, cumprimento, irregularidade, transferencia, alteração, cumprimento,\n",
      "\n",
      "Cluster 12, Count: 9981 \n",
      "Main terms: cobrança, cobrança, indevida, valor, cobrança, produtos,\n",
      "\n",
      "Cluster 13, Count: 40184 \n",
      "Main terms: celular, telefone, celular, telefone, cobrança, indevida,\n",
      "\n",
      "Cluster 14, Count: 6559 \n",
      "Main terms: artigo, etc, cozinha, etc, louça, etc,\n",
      "\n",
      "Cluster 15, Count: 24843 \n",
      "Main terms: garantia, abrangência, garantia, abrangência, garantia, cobertura,\n",
      "\n",
      "Cluster 16, Count: 36715 \n",
      "Main terms: interfone, etc, etc, interfone, convencional, convencional,\n",
      "\n",
      "Cluster 17, Count: 26064 \n",
      "Main terms: satélite, satélite, cabo, cabo, assinatura, assinatura,\n",
      "\n",
      "Cluster 18, Count: 21146 \n",
      "Main terms: impróprio, vicio, inadequado, executado, executado, qualidade,\n",
      "\n",
      "Cluster 19, Count: 23394 \n",
      "Main terms: geladeira, freezer, freezer, geladeira, geladeira, freezer,\n",
      "\n",
      "Cluster 20, Count: 15130 \n",
      "Main terms: contrato, outros, contrato, outros, outros, contrato,\n",
      "\n",
      "Cluster 21, Count: 19134 \n",
      "Main terms: energia, energia, energia, elétrica, elétrica, elétrica,\n",
      "\n",
      "Cluster 22, Count: 25265 \n",
      "Main terms: banco, comercial, comercial, banco, banco, comercial,\n",
      "\n",
      "Cluster 23, Count: 15597 \n",
      "Main terms: contrato, orçamento, pedido, contrato, pedido, descumprimento,\n",
      "\n",
      "Cluster 24, Count: 15059 \n",
      "Main terms: água, esgoto, esgoto, água, esgoto, água,\n",
      "\n",
      "Cluster 25, Count: 12674 \n",
      "Main terms: ar, condicionado, condicionado, circulador, aquecedor, aquecedor,\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py:13: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#ix-indexer-is-deprecated\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster 26, Count: 14662 \n",
      "Main terms: incorporação, construtoras, construtoras, incorporação, incorporação, contrato,\n",
      "\n",
      "Cluster 27, Count: 13318 \n",
      "Main terms: duvidas, duvidas, duvidas, sobre, sobre, cobrança,\n",
      "\n",
      "Cluster 28, Count: 35283 \n",
      "Main terms: entrega, entrega, demora, entrega, entrega, demora,\n",
      "\n",
      "Cluster 29, Count: 3774 \n",
      "Main terms: entrega, financeira, contrato, compra, valor, rescisão,\n",
      "\n",
      "Cluster 30, Count: 12895 \n",
      "Main terms: publicidade, publicidade, enganosa, oferta, venda, cursos,\n",
      "\n",
      "Cluster 31, Count: 14153 \n",
      "Main terms: compra, desistência, cancelamento, desistência, compra, compra,\n",
      "\n",
      "Cluster 32, Count: 9803 \n",
      "Main terms: calculo, calculo, prestação, taxas, cartão, cartão,\n",
      "\n",
      "Cluster 33, Count: 12131 \n",
      "Main terms: turísticos, pacotes, pacotes, viagens, operadoras, agências,\n",
      "\n",
      "Cluster 34, Count: 29932 \n",
      "Main terms: cassete, video-laser, televisão, filmadora, filmadora, cassete,\n",
      "\n",
      "Cluster 35, Count: 13276 \n",
      "Main terms: seguro, saúde, outros, indevida, cobrança, cobrança,\n",
      "\n",
      "Cluster 36, Count: 12019 \n",
      "Main terms: quarto, móveis, móveis, produtos, vício, produtos,\n",
      "\n",
      "Cluster 37, Count: 15690 \n",
      "Main terms: produtos, vício, produtos, máquina, água, internet,\n",
      "\n",
      "Cluster 38, Count: 13527 \n",
      "Main terms: saúde, plano, plano, regulamentado, saúde, plano,\n",
      "\n",
      "Cluster 39, Count: 15345 \n",
      "Main terms: falta, falta, reposição, peca, peca, falta,\n",
      "\n",
      "Cluster 40, Count: 3940 \n",
      "Main terms: frutas, loja, comercial, serviço, abusiva, cobrança,\n",
      "\n",
      "Cluster 41, Count: 12329 \n",
      "Main terms: imediata, resposta, suspensão, suspensão, suspensão, sac,\n",
      "\n",
      "Cluster 42, Count: 12019 \n",
      "Main terms: serviço, fornecido, assistência, etc, banco, produtos,\n",
      "\n",
      "Cluster 43, Count: 12546 \n",
      "Main terms: escolares, superior, graus, graus, escolares, escolares,\n",
      "\n",
      "Cluster 44, Count: 12752 \n",
      "Main terms: loja, cartão, cartão, cobrança, indevida, cobrança,\n",
      "\n",
      "Cluster 45, Count: 1050 \n",
      "Main terms: acesso, provedor, provedor, provedor, acesso, ex,\n",
      "\n",
      "Cluster 46, Count: 7836 \n",
      "Main terms: consignado, crédito, crédito, financeira, outros, problemas,\n",
      "\n",
      "Cluster 47, Count: 12022 \n",
      "Main terms: fogão, fogão, microondas, produtos, vício, produtos,\n",
      "\n",
      "Cluster 48, Count: 10824 \n",
      "Main terms: móveis, produtos, vício, cozinha, produtos, incompleta,\n",
      "\n",
      "Cluster 49, Count: 10256 \n",
      "Main terms: venda, enganosa, venda, artigo, livros, outros,\n",
      "\n",
      "Cluster 50, Count: 6042 \n",
      "Main terms: importado, importado, produtos, produtos, vício, outros,\n",
      "\n",
      "Cluster 51, Count: 13430 \n",
      "Main terms: financiamento, antecipação, antecipação, banco, banco, comercial,\n",
      "\n",
      "Cluster 52, Count: 17263 \n",
      "Main terms: cobrança, indevida, abusiva, cobrança, indevida, cobrança,\n",
      "\n",
      "Cluster 53, Count: 8867 \n",
      "Main terms: produtos, pedido, entrega, produtos, móveis, incompleta,\n",
      "\n",
      "Cluster 54, Count: 5912 \n",
      "Main terms: consignado, crédito, banco, crédito, banco, comercial,\n",
      "\n",
      "Cluster 55, Count: 5878 \n",
      "Main terms: outros, outros, produtos, pessoal, secadora, produtos,\n",
      "\n",
      "Cluster 56, Count: 10339 \n",
      "Main terms: aparelho, vício, produtos, produtos, acessório, elétrica,\n",
      "\n",
      "Cluster 57, Count: 4824 \n",
      "Main terms: frutas, etc, etc, etc, produtos, vício,\n",
      "\n",
      "Cluster 58, Count: 3244 \n",
      "Main terms: retenção, financeira, entrega, prazo, loja, seguro,\n",
      "\n",
      "Cluster 59, Count: 29695 \n",
      "Main terms: danos, contrato, cumprimento, serviço, desistência, assistência,\n",
      "\n",
      "Cluster 60, Count: 9634 \n",
      "Main terms: freezer, geladeira, geladeira, abrangência, garantia, garantia,\n",
      "\n",
      "Cluster 61, Count: 12870 \n",
      "Main terms: secadora, louça, secadora, roupa, máquina, lavar,\n",
      "\n",
      "Cluster 62, Count: 6152 \n",
      "Main terms: problemas, sac, acesso, serviço, telefone, celular,\n",
      "\n",
      "Cluster 63, Count: 15183 \n",
      "Main terms: financeira, financeira, financeira, cobrança, indevida, cobrança,\n",
      "\n",
      "Cluster 64, Count: 8362 \n",
      "Main terms: cartão, cartão, crédito, serviço, banco, entrega,\n",
      "\n",
      "Cluster 65, Count: 6248 \n",
      "Main terms: descumprimento, prazo, garantia, telefone, celular, assistência,\n",
      "\n",
      "Cluster 66, Count: 9732 \n",
      "Main terms: eletroeletrônico, eletroeletrônico, importado, importado, produtos, vício,\n",
      "\n",
      "Cluster 67, Count: 4489 \n",
      "Main terms: entrega, filmadora, cassete, vídeo, vídeo, cassete,\n",
      "\n",
      "Cluster 68, Count: 4794 \n",
      "Main terms: financeira, cobrança, serviço, banco, valor, recusa,\n",
      "\n",
      "Cluster 69, Count: 7907 \n",
      "Main terms: carro, produtos, vício, produtos, compra, entrega,\n",
      "\n",
      "Cluster 70, Count: 11600 \n",
      "Main terms: rescisão, rescisão, unilateral, contrato, contrato, alteração,\n",
      "\n",
      "Cluster 71, Count: 7024 \n",
      "Main terms: prestação, calculo, antecipação, banco, banco, comercial,\n",
      "\n",
      "Cluster 72, Count: 14149 \n",
      "Main terms: provedor, informática, provedor, provedor, ex, acesso,\n",
      "\n",
      "Cluster 73, Count: 12139 \n",
      "Main terms: recusa, serviço, telefone, celular, telefone, fornecido,\n",
      "\n",
      "Cluster 74, Count: 5931 \n",
      "Main terms: etc, etc, garantia, abrangência, garantia, abrangência,\n",
      "\n",
      "Cluster 75, Count: 30794 \n",
      "Main terms: crédito, cartão, crédito, cartão, crédito, cartão,\n",
      "\n",
      "Cluster 76, Count: 5546 \n",
      "Main terms: retenção, cancelamento, sac, demora, serviço, telefone,\n",
      "\n",
      "Cluster 77, Count: 5267 \n",
      "Main terms: outros, outros, contrato, serviço, entrega, retenção,\n",
      "\n",
      "Cluster 78, Count: 7192 \n",
      "Main terms: vestuário, acessório, produtos, vício, produtos, roupa,\n",
      "\n",
      "Cluster 79, Count: 6976 \n",
      "Main terms: entrega, entrega, oferta, serviço, fornecido, fornecido,\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#ploting main finds about clusters\n",
    "\n",
    "problems = {'problem': descricaoAssuntoProblemaAdjusted, 'cluster': clusters}\n",
    "clustersFrame = pd.DataFrame(problems, index = [clusters] , columns = ['problem', 'cluster'])\n",
    "\n",
    "orderCentroids = km.cluster_centers_.argsort()[:, ::-1] \n",
    "\n",
    "for i in range(numClusters):\n",
    "    clusterCount = clustersFrame[clustersFrame['cluster'] == i]['cluster'].value_counts()\n",
    "    print(\"Cluster %d, Count: %d \\nMain terms:\" % (i, clusterCount), end='')\n",
    "    \n",
    "    for ind in orderCentroids[i, :6]: #replace 6 with n words per cluster\n",
    "        print(' %s' % vocabularyDescription.ix[terms[ind].split(' ')].values.tolist()[0][0], end=',')\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "#Ploting clusters distribution chart\n",
    "fig = plt.figure(figsize = (10, 10))\n",
    "ax = plt.axes()\n",
    "plt.scatter(tfidfEmbedded[:, 0], tfidfEmbedded[:, 1], marker = \"x\", c = km.labels_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add cluster to procon database\n",
    "proconResult = procon\n",
    "\n",
    "clusterSerie = pd.Series(clusters)\n",
    "assuntoProblemaSerie = pd.Series(descricaoAssuntoProblemaAdjusted)\n",
    "proconResult['cluster'] = clusterSerie.values\n",
    "proconResult['descAssuntoProblema'] = assuntoProblemaSerie.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create data frame with clusters final results with problems description\n",
    "\n",
    "#Print the final procon database\n",
    "proconResult.to_csv(\"data//final//consumer-complaints-clustering-result.csv\", sep='\\t', encoding='utf-8')\n",
    "\n",
    "\n",
    "#Print only descricaoAssuntoProblema with clusters\n",
    "#dfResult = pd.DataFrame(dict(label=clusters, title=descricaoAssuntoProblemaAdjusted))\n",
    "#dfResult.to_csv(\"data//clustersResult.csv\", sep='\\t', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "1a26e4b7189bf03eb81522675f6e6c88684ba722547c6ad443d3676f771c332f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
